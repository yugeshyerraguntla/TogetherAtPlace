# TogetherAtPlace
Link for all repositories

Data ---> Feature Engineering ---> Handle Categorical Features ---> Feature Selection 


1. Feature Engineering        -- [FEATURE ENGINEERING TECHNIQUES](https://github.com/yugeshyerraguntla/FeatureEngineeringTechniques)
    - Handling Missing Data - (Mean/MedianMode Replacement, Random Sample Imputation, Capturing NaN values, EoD Imputation, Arbitrary Imputation)
    - Handling Categorical Variables - (Highest Count, (Nominal and Ordinal Variables)-One Hot Encoding, Count Frequency Encoding)
    - Feature Scaling - (Normalization, Standardization)


2. Feature Selection          -- [FEATURE SELECTION TECHNIQUES](https://github.com/yugeshyerraguntla/FeatureSelectionTechniques)
    - Dropping Constan Features - (Variance Threshold)
    - Correlation 
    - Information Gain - Mutual Information Gain
    - Chi Square - Fisher Score (For Feature Selection)
    - KBestAlgorithm


3. Handling Imbalanced Data   -- [HANDLING IMBALANCED DATA](https://github.com/yugeshyerraguntla/HandlingImbalancedData)
    - Try reducing FP and FN. Look at your Performance Metrics and apply SMOTE TECHNIQUES
    - If nothing works, go for Ensmble techniques


4. Hypothesis Testing         -- [HYPOTHESIS TESTING](https://github.com/yugeshyerraguntla/HypothesisTesting---T-ChiSquare-Anova)
    - T Test
    - ChiSquare Test
    - ANOVA Test

5. Types of Transformation    --

6. Types of Cross Validation  --

7. Hyperprameter Optimization --



**Machine Learning Algorithms:**

- [All Basic ML Models](https://github.com/yugeshyerraguntla/Basic-MachineLearning-Models)
  - Linear, Logistic, RandomForest, KNN, KMeans, NLP, SVM


- [Linear Regression](https://github.com/yugeshyerraguntla/Linear-Regression-Simple-Ridge-Lasso-Multiple-Polynomial)
  - Includes Simple Linear Reg, Ridge Reg, Lasso Reg, Multiple Reg, Polynomial Reg.


- [Decision Trees](https://github.com/yugeshyerraguntla/DecisionTrees)


- [Logistic Regression](https://github.com/yugeshyerraguntla/LogisticRegression)


- [Naive Bayes](https://github.com/yugeshyerraguntla/NaiveBayes)


- [KNearestNeighbours](https://github.com/yugeshyerraguntla/KNearestNeighbours)


- [CLUSTERING - KMeans, DBSCAN](https://github.com/yugeshyerraguntla/Clustering-KMeans-DBSCAN)


- [ENSEMBLE TECHNIQUES](https://github.com/yugeshyerraguntla/EnsembleLearning---Comparing-Various-Models)

  - [ENSEMBLE - Bagging](https://github.com/yugeshyerraguntla/Ensemble-Bagging)
    - Bootstrap Aggregation - Randomforest

  - [ENSEMBLE - Boosting](https://github.com/yugeshyerraguntla/Ensemble-Boosting)
    -  ADA Boost
    -  XG Boost




**Sample ML Projects:**

- [500+ AI-ML Projects](https://github.com/yugeshyerraguntla/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code)

- [2019 WorldCup Winner Predictor with RF](https://github.com/yugeshyerraguntla/2019-ICC-WorldCupPredictor_RF)

- [Drowsiness Detection](https://github.com/yugeshyerraguntla/DrowsinessDetection)








